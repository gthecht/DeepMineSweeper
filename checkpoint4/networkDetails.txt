without relu?
Network details:
trained on 100,000 games (90% for training 10% for validation)
and with 20 epochs
success rate 0.411
CNet.summary():
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1 (Conv2D)               (None, 14, 14, 32)        320       
_________________________________________________________________
conv2 (Conv2D)               (None, 12, 12, 64)        18496     
_________________________________________________________________
conv3 (Conv2D)               (None, 10, 10, 128)       73856     
_________________________________________________________________
deconv1 (Conv2DTranspose)    (None, 12, 12, 128)       147584    
_________________________________________________________________
deconv2 (Conv2DTranspose)    (None, 14, 14, 128)       147584    
_________________________________________________________________
deconv3 (Conv2DTranspose)    (None, 16, 16, 64)        73792     
_________________________________________________________________
dense1 (Dense)               (None, 16, 16, 1)         65        
=================================================================
Total params: 461,697
Trainable params: 461,697
Non-trainable params: 0